---
title: "Batch-BO-example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Batch-BO-example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rgl.printRglwidget = TRUE)
```

```{r setup}
library(TSBatchBO)
library(lhs)
library(rgl)
```

## Simulation Function

Consider the following function `foo` which takes a two-dimensional vector $(x_1, x_2)$ 
as input with $0 \le x_i \le 1, \; \forall i$ and returns a scalar output. 

```{r}
foo <- function(X)
 {
  if(is.null(nrow(X))) X <- matrix(X, nrow=1)
  m <- 8.6928
  s <- 2.4269
  x1 <- 4*X[,1] - 2
  x2 <- 4*X[,2] - 2
  a <- 1 + (x1 + x2 + 1)^2 * 
    (19 - 14*x1 + 3*x1^2 - 14*x2 + 6*x1*x2 + 3*x2^2)
  b <- 30 + (2*x1 - 3*x2)^2 * 
    (18 - 32*x1 + 12*x1^2 + 48*x2 - 36*x1*x2 + 27*x2^2)
  f <- log(a*b)
  f <- (f - m)/s + rnorm(1, sd = 0.1)
  return(f)
 }
```

## Initial design and search space

We design a set of 1000 uniform LHS samples from the unit box, which the 
minimizer of `foo` will be searched over. 20 points among those 1000 are randomly
picked to evaluate to start the optimization.

```{r, fig.align='center', fig.height=5, fig.width=5}
set.seed(1)
N <- 1000
n1 <- 20
Xgrid <- randomLHS(N, 2)
init_id <- sample(N, n1)

col_vec <- rep("grey", N)
col_vec[init_id] <- "red"
pairs(Xgrid, col = col_vec, cex = 0.8, labels = c(expression(x[1]), expression(x[2])))

## evaluate 
X <- Xgrid[init_id, ]
Y <- apply(X, 1, foo)

plot3d(X[,1], X[,2], Y)

## save the current best and keep track of it
f_best <- c()
X_best <- matrix(NA, nrow = 0, ncol = 2)

f_best <- c(f_best, min(Y))
X_best <- rbind(X_best, X[which.min(Y), ])
cat(">> iter = ", 0, "| current best value = ", 
                f_best[1], "at x1 = ", X_best[1, 1], ", x2 = ", X_best[1, 2], "\n")
```

## Bayesian Optimization

```{r}
nstep <- 30 # times the optimization loop should run
npoints <- 10 # size of the batch evaluation in each iteration

## fit GP on initial data
gp <- hetGP::mleHomGP(X, Y, covtype = "Gaussian")

for (i in 1:nstep){
  
  ## next batch of points for evaluation based on Thompson sampling
  X_new <- TS_npoints(model = gp, npoints = npoints, Xgrid = Xgrid)
  
  ## evaluate
  Y_new <- apply(X_new, 1, foo)
  
  ## update GP
  f <- update(gp, X_new, Y_new)
  
  ## store the new best
  X <- rbind(X, X_new)
  Y <- c(Y, Y_new)
  f_best <- c(f_best, min(Y))
  X_best <- rbind(X_best, X[which.min(Y), ])
  cat(">> iter = ", i, "| current best value = ", 
                  f_best[i+1], "at x1 = ", X_best[i+1, 1], ", x2 = ", X_best[i+1, 2], "\n")
}
```

Now we look at the result after 30 iteration

```{r, fig.align='center', fig.height=5, fig.width=5}
plot3d(X[,1], X[,2], Y, col = rgb(seq(0, 1, length.out = nstep + 1), 0, 0))
```

